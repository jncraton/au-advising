#!/usr/bin/python3

import os
import pandas as pd


def scrape_largest_table(url, drop_cols):
    # fetch all tables from the url and return the largest table
    try:
        tables = pd.read_html(url)
        if not tables:
            return None

        largest = max(tables, key=lambda df: (df.shape[0], df.shape[1]))
        df = largest.fillna("")
        df.columns = df.columns.astype(str)

        exclude_sections = {'5E', '8E', '8ES'}
        section_col = 'class section'
        if section_col in df.columns:
            df = df[~df[section_col].astype(str).isin(exclude_sections)]
            
        to_drop = [c for c in df.columns if c.lower() in {d.lower() for d in drop_cols}]
        df_filtered = df.drop(columns=to_drop, errors="ignore")

        descr_cols = [c for c in df_filtered.columns if c.lower() == "descr"]
        if descr_cols:
            col = descr_cols[0]

            def _clean_descr(x):
                s = str(x)
                for tag in ("(23)", "(24)", "(25)"):
                    i = s.find(tag)
                    if i != -1:
                        s = s[:i]
                        break
                return s.strip()

            df_filtered[col] = df_filtered[col].astype(str).apply(_clean_descr)

        return df_filtered
    except Exception:
        return None


if __name__ == "__main__":
    # Note that prereqs do not work here currently
    drop_cols = ['term', 'class section', 'start dt', 'end dt', 'class nbr', 'sectn req', 'topic', 'instr', 'grd', 'department', 'prereqs', 'cap', 'combined section', 'class stat', 'consent']
    term_names = ["", "fall", "", "spring", "summer"]
    for term in ["2251", "2253", "2261", "2263"]:
        target_url = f"https://basilisk.anderson.edu:4500/under_graduates.aspx?ListBox3={term}"

        year = int(term[1:3])
        filename = f"references/20{year}-{year+1}/schedule-{term_names[int(term[-1])]}.tsv"
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        df = scrape_largest_table(target_url, drop_cols)
        if df is None:
            # create an empty file to signal failure
            open(filename, "w").close()
        else:
            df.to_csv(filename, sep="\t", index=False, encoding="utf-8")
